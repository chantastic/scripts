#!/usr/bin/env python3
"""
Rough Cut - Video Timeline Generator

Generates OTIO (OpenTimelineIO) timeline from video with automatic:
- Silence removal (ffmpeg silencedetect)
- Empty clip removal (no transcript = noise)
- Duplicate take detection (whisper transcript analysis)

OTIO was chosen as the interchange format over EDL (single track, no markers,
no metadata), AAF (binary, hard to generate), and hand-rolled FCPXML (verbose,
FCP-specific, no ffmpeg path). OTIO is JSON-based, has a Python-first API, and
built-in adapters for FCPXML, EDL, and AAF.

Each script in the pipeline is atomic â€” reads .otio, transforms it, writes .otio.
Export is a separate step so the same timeline can target FCP, ffmpeg, etc.

Usage:
    rough-cut <video_path> [options]
    rough-cut --test         # Run tests

Outputs:
    <video>.json     - Whisper transcript
    <video>.otio     - OpenTimelineIO timeline

Pipeline:
    rough-cut my-video.mov           # produce .otio
    add-broll my-video.otio          # augment with B-roll markers
    export-cut my-video.otio         # export to FCPXML, ffmpeg, etc.

Example:
    rough-cut my-video.mov
    rough-cut my-video.mov --post-roll 4
"""

import argparse
import logging
import sys
import tempfile
import unittest
import uuid
from pathlib import Path

try:
    import opentimelineio as otio
except ImportError:
    print("Error: opentimelineio required. Install with: pip install opentimelineio")
    sys.exit(1)

from rc_common import RoughCutError
from rc_audio import extract_audio, transcribe_audio, load_transcript, get_video_duration, get_transcript_for_segment
from rc_silence import detect_silences, load_silences, invert_silences
from rc_takes import detect_takes

logging.basicConfig(
    level=logging.INFO,
    format='%(message)s'
)
logger = logging.getLogger(__name__)


def build_otio_timeline(intervals, take_markers, video_path, duration, post_roll_frames=2, fps=30):
    """Build an OTIO timeline from speech intervals"""

    timeline = otio.schema.Timeline(name="Rough Cut")
    timeline.metadata["rough-cut"] = {
        "source_video": str(video_path),
        "video_duration": duration,
        "fps": fps,
    }

    track = otio.schema.Track(name="Main", kind=otio.schema.TrackKind.Video)

    for i, interval in enumerate(intervals):
        media_ref = otio.schema.ExternalReference(
            target_url=Path(video_path).as_uri(),
            available_range=otio.opentime.TimeRange(
                start_time=otio.opentime.RationalTime(0, fps),
                duration=otio.opentime.RationalTime(int(duration * fps), fps)
            )
        )

        start_frames = int(interval['start'] * fps)
        duration_frames = int(interval['duration'] * fps) + post_roll_frames

        clip = otio.schema.Clip(
            name=interval.get('text', '').strip()[:40] or f"Clip {i+1}",
            media_reference=media_ref,
            source_range=otio.opentime.TimeRange(
                start_time=otio.opentime.RationalTime(start_frames, fps),
                duration=otio.opentime.RationalTime(duration_frames, fps)
            ),
            metadata={
                "rough-cut": {
                    "transcript": interval.get('text', ''),
                    "transcript_indices": interval.get('indices', []),
                }
            }
        )

        if i in take_markers:
            info = take_markers[i]
            marker = otio.schema.Marker(
                name=f"{info['removed_count']} takes removed",
                marked_range=otio.opentime.TimeRange(
                    start_time=otio.opentime.RationalTime(0, fps),
                    duration=otio.opentime.RationalTime(1, fps)
                ),
                color=otio.schema.MarkerColor.RED,
                metadata={
                    "rough-cut": {
                        "type": "take",
                        "removed_count": info['removed_count'],
                        "sample_text": info['sample_text'],
                    }
                }
            )
            clip.markers.append(marker)

        track.append(clip)

    timeline.tracks.append(track)
    return timeline


def main():
    parser = argparse.ArgumentParser(
        description='Generate OTIO timeline with automatic silence removal and take detection',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  rough-cut my-video.mov
  rough-cut my-video.mov --post-roll 4

Outputs:
  my-video.json     - Whisper transcript
  my-video.otio     - OpenTimelineIO timeline
        """
    )

    parser.add_argument('video_path', help='Path to video file')
    parser.add_argument('--post-roll', type=int, default=2, help='Post-roll frames (default: 2)')
    parser.add_argument('--min-speech', type=float, default=0.3, help='Min speech segment duration in seconds (default: 0.3)')
    parser.add_argument('--min-matching-words', type=int, default=3, help='Words to match for takes (default: 3)')
    parser.add_argument('--silence-threshold', type=int, default=-45, help='Silence threshold in dB (default: -45)')

    args = parser.parse_args()

    video_path = Path(args.video_path).resolve()
    if not video_path.exists():
        logger.error(f"Video file not found: {video_path}")
        sys.exit(1)

    video_stem = video_path.stem
    video_dir = video_path.parent
    transcript_path = video_dir / f"{video_stem}.json"
    otio_path = video_dir / f"{video_stem}.otio"

    session_id = str(uuid.uuid4())[:8]
    temp_audio = Path(tempfile.gettempdir()) / f"rough-cut-{session_id}-audio.wav"
    temp_silences = Path(tempfile.gettempdir()) / f"rough-cut-{session_id}-silences.txt"

    try:
        logger.info(f"Processing: {video_path.name}")
        logger.info("=" * 50)

        # 1. External tools
        extract_audio(video_path, temp_audio)
        transcribe_audio(temp_audio, transcript_path)
        logger.info(f"  Saved transcript: {transcript_path.name}")
        detect_silences(video_path, temp_silences, threshold_db=args.silence_threshold)

        # 2. Load data
        logger.info("\nLoading data...")
        transcript = load_transcript(transcript_path)
        logger.info(f"  {len(transcript)} transcript segments")

        silences = load_silences(temp_silences)
        duration = get_video_duration(video_path)
        logger.info(f"  Duration: {duration/60:.1f} min")

        # 3. Build speech intervals (invert silences)
        logger.info("\nBuilding speech intervals...")
        speech_intervals = invert_silences(silences, duration, min_speech=args.min_speech)
        logger.info(f"  {len(speech_intervals)} speech intervals")

        total_speech = sum(s['duration'] for s in speech_intervals)
        logger.info(f"  Speech duration: {total_speech/60:.1f} min ({total_speech/duration*100:.0f}% of original)")

        # 4. Label intervals with transcript text
        logger.info("\nLabeling intervals with transcript...")
        for interval in speech_intervals:
            interval['text'], interval['indices'] = get_transcript_for_segment(
                transcript, interval['start'], interval['end'])

        # 5. Remove empty clips (noise that bypassed silence detection)
        # Silence detection misses low-grade noise (fan hum, typing, desk bumps).
        # These intervals survive as "speech" but whisper produces no transcript
        # for them. No transcript = not speech. This MUST run before take detection
        # (step 6), otherwise take matching could pair noise clips with real speech.
        logger.info("\nFiltering empty clips...")
        before_count = len(speech_intervals)
        speech_intervals = [s for s in speech_intervals if s.get('text', '').strip()]
        removed_empty = before_count - len(speech_intervals)
        logger.info(f"  Removed {removed_empty} empty clips (noise)")

        # 6. Detect + remove duplicate takes
        logger.info("\nDetecting duplicate takes...")
        removes, take_markers = detect_takes(speech_intervals, args.min_matching_words)
        logger.info(f"  {len(removes)} takes to remove")
        final_intervals = [s for i, s in enumerate(speech_intervals) if i not in removes]

        # Remap take_markers to final_intervals indices
        final_markers = {}
        final_idx = 0
        for i, s in enumerate(speech_intervals):
            if i in removes:
                continue
            if i in take_markers:
                final_markers[final_idx] = take_markers[i]
            final_idx += 1

        # 7. Build OTIO timeline
        logger.info("\nBuilding OTIO timeline...")
        timeline = build_otio_timeline(
            final_intervals, final_markers, video_path,
            duration, args.post_roll
        )

        otio.adapters.write_to_file(timeline, str(otio_path))
        logger.info(f"  Saved timeline: {otio_path.name}")

        # Summary
        total_frames = sum(
            int(clip.source_range.duration.value)
            for clip in timeline.tracks[0]
            if isinstance(clip, otio.schema.Clip)
        )
        fps = 30

        logger.info("\n" + "=" * 50)
        logger.info("SUMMARY")
        logger.info("=" * 50)
        logger.info(f"Original duration:  {duration/60:.1f} min")
        logger.info(f"Final duration:     {total_frames/fps/60:.1f} min")
        logger.info(f"Time saved:         {(duration - total_frames/fps)/60:.1f} min ({(1 - total_frames/fps/duration)*100:.0f}%)")
        logger.info(f"Clips:              {len(final_intervals)}")
        logger.info(f"Empty removed:      {removed_empty}")
        logger.info(f"Takes removed:      {len(removes)}")
        logger.info(f"\nOutputs:")
        logger.info(f"  {transcript_path}")
        logger.info(f"  {otio_path}")
        logger.info(f"\nNext steps:")
        logger.info(f"  add-broll {otio_path.name}          # add B-roll markers")
        logger.info(f"  export-cut {otio_path.name}         # export to FCPXML/ffmpeg")

        logger.info("\nCleaning up...")
        temp_audio.unlink(missing_ok=True)
        temp_silences.unlink(missing_ok=True)

        logger.info("Done!")

    except RoughCutError as e:
        logger.error(f"\nError: {e}")
        temp_audio.unlink(missing_ok=True)
        temp_silences.unlink(missing_ok=True)
        sys.exit(1)
    except KeyboardInterrupt:
        logger.info("\n\nInterrupted by user")
        temp_audio.unlink(missing_ok=True)
        temp_silences.unlink(missing_ok=True)
        sys.exit(130)
    except Exception as e:
        logger.error(f"\nUnexpected error: {e}")
        temp_audio.unlink(missing_ok=True)
        temp_silences.unlink(missing_ok=True)
        sys.exit(1)


def run_tests():
    """Discover and run tests from tests/ directory"""
    print("Running rough-cut tests...")
    print("=" * 50)

    loader = unittest.TestLoader()
    tests_dir = Path(__file__).parent / 'tests'
    suite = loader.discover(str(tests_dir), pattern='test_*.py', top_level_dir=str(Path(__file__).parent))

    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    print("\n" + "=" * 50)
    if result.wasSuccessful():
        print(f"All {result.testsRun} tests passed!")
        return 0
    else:
        print(f"{len(result.failures)} failures, {len(result.errors)} errors")
        return 1


if __name__ == '__main__':
    if '--test' in sys.argv:
        sys.exit(run_tests())
    else:
        main()
